- "system under test"

- "test case"
  - independent
  - no side effects

- "unit test"
  - checks the behavior of an _element of code_
    - a method or function
    - a module or class
  - automated
    - is designed by a human
    - runs without intervention
    - reports results unambiguously as "pass" or "fail"
  - does not use
    - the file system
    - a database
    - the network
    - external resources

- "test runner"
  - a program that executes test cases

- "test suite"
  - a number of test cases executed together by a test runner

- "test fixture"
  - a piece of code that can construct and configure your test case/suite/run (e.g. setUp())
  - can clean up following execution of test case/suite/run (e.g. **tearDown())
  - *generally, memory manager automatically takes care of cleanup in unittests
  - *is not executed if setUp() throws an exception

- "regression" - something that used to work no longer does

- "test last"
  1) write code
  2) design tests
  3) **debug & rework
  - pro: don't invest in test cases until design is stable (can avoid rewrites in best case)
  - risk: discover testability problems and bugs late in the process
  - risk: you'll rush or skip designing the tests
- "test first"
  1) design code (basic interface)
  2) design tests
  3) write code (full implementation)
  4) refactor tests/refactor code
  - risk: large amount of rework
- "test driven"
  1) write one test
  2) write code to pass the test
  3) refactor
  - pro: iterative and emergent

- "continuous integration"
  - server that listens for changes in version control
  - runs test suite and alerts team of failures

- python -m unittest -q test_phonebook.PhoneBookTest.test_lookup_entry_by_name
  - just run one spec
- python -m unittest -v
  - verbose mode; will give you spec name

- skip a test
  - `@unittest.skip('WIP')` decorator

- DESIGN
  - Test Case Name
    - ACT: Set up object to be tested and its collaborators
    - ARRANGE: Exercise functionality on the object
    - ASSERT: Make claims about the object and its collaborators
    - CLEANUP: Release resources, restore to original state
  - One assertion per test
    - a test case breaks as soon as it encounters a failed assertion
    - all subsequent assertions are not run, so no conclusions can be drawn
    - thus, one assertion per test case is ideal

- WHY TEST?
  - Understand what to build
  - Document the units
    - "executable specification"
  - Design the units
    - decompose the problem into units that are independently testable
      - loose coupling
    - design the interface separately from the implementation
  - Regression protection

- LIMITATIONS ON UNIT TESTING
  - Can't find all the errors
  - Won't find integration errors
  - Not good at testing non functional reqs (e.g. performance & security)
